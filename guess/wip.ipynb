{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6118f3b4-930b-4a78-b505-86335462c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning\n",
    "import lightning.pytorch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a29d1f-edcb-400b-8d39-0a8f70000579",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = pl.scan_parquet(\"../../fishnet-position-dataset/endgame_evals.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218602a3-014a-443a-acf9-c8061d43bc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>piece_count</th><th>len</th></tr><tr><td>u8</td><td>u32</td></tr></thead><tbody><tr><td>2</td><td>1850480</td></tr><tr><td>3</td><td>118569229</td></tr><tr><td>4</td><td>173072838</td></tr><tr><td>5</td><td>212005402</td></tr><tr><td>6</td><td>254848650</td></tr><tr><td>7</td><td>297170292</td></tr><tr><td>8</td><td>343192392</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌─────────────┬───────────┐\n",
       "│ piece_count ┆ len       │\n",
       "│ ---         ┆ ---       │\n",
       "│ u8          ┆ u32       │\n",
       "╞═════════════╪═══════════╡\n",
       "│ 2           ┆ 1850480   │\n",
       "│ 3           ┆ 118569229 │\n",
       "│ 4           ┆ 173072838 │\n",
       "│ 5           ┆ 212005402 │\n",
       "│ 6           ┆ 254848650 │\n",
       "│ 7           ┆ 297170292 │\n",
       "│ 8           ┆ 343192392 │\n",
       "└─────────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan.group_by(\"piece_count\").len().sort(\"len\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445c0c08-a921-454d-89c3-290521b0b7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>op1</th><th>len</th></tr><tr><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>false</td><td>152134204</td></tr><tr><td>true</td><td>191058188</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬───────────┐\n",
       "│ op1   ┆ len       │\n",
       "│ ---   ┆ ---       │\n",
       "│ bool  ┆ u32       │\n",
       "╞═══════╪═══════════╡\n",
       "│ false ┆ 152134204 │\n",
       "│ true  ┆ 191058188 │\n",
       "└───────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan.filter(pl.col(\"piece_count\") == 8).group_by(\"op1\").len().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca5fa156-a6cb-40e1-85a3-81aff522463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 14 * 64 + 1\n",
    "HIDDEN_DIM = 0\n",
    "\n",
    "PIECE_TO_PLANE = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11,\n",
    "}\n",
    "\n",
    "PIECE_VALUE = {\n",
    "    'P': 1, 'N': 3, 'B': 3, 'R': 5, 'Q': 9, 'K': 0,\n",
    "    'p': -1, 'n': -3, 'b': -3, 'r': -5, 'q': -9, 'k': 0,\n",
    "}\n",
    "\n",
    "def fen_to_onehot(fen):\n",
    "    board, turn, ep, _ = fen.split(\" \", 3)\n",
    "    tensor = torch.zeros(DIM + HIDDEN_DIM, dtype=torch.float32)\n",
    "    x = 0\n",
    "    material_balance = 0\n",
    "    for ch in board:\n",
    "        if ch.isdigit():\n",
    "            x += int(ch)\n",
    "        elif ch == \"/\":\n",
    "            continue\n",
    "        else:\n",
    "            tensor[64 * PIECE_TO_PLANE[ch] + (x ^ 0x38)] = 1\n",
    "            material_balance += PIECE_VALUE[ch]\n",
    "            x += 1\n",
    "    if ep != \"-\":\n",
    "        x = (ord(ep[0]) - ord(\"a\")) * 8 + (ord(ep[1]) - ord(\"1\"))\n",
    "        tensor[64 * (12 if turn == \"w\" else 13) + x] = 1\n",
    "    tensor[DIM - 1] = int(turn == \"w\")\n",
    "    #tensor[DIM] = material_balance\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7be2a0b8-e1b9-4830-901f-799e2337d090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fen_to_onehot(\"4k3/8/8/8/8/8/8/R3K3 w - - 0 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de263e7-4d5d-44e2-873c-e94f42012230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scan.filter(\n",
    "    pl.col(\"piece_count\").eq(8) &\n",
    "    pl.col(\"op1\") &\n",
    "    pl.col(\"cp\").abs().gt(50).fill_null(True)\n",
    ").select(\n",
    "    pl.col(\"fen\"),\n",
    "    (pl.col(\"cp\").fill_null(0).gt(0) | pl.col(\"mate\").fill_null(0).gt(0)).alias(\"win\")\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76eb97d-fad6-4284-94ed-186871f4c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (148_818_672, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>fen</th><th>win</th></tr><tr><td>str</td><td>bool</td></tr></thead><tbody><tr><td>&quot;r5k1/5p1p/4p3/8/8/4K1P1/7P/8 b…</td><td>false</td></tr><tr><td>&quot;6k1/5p1p/4p3/8/8/4K1P1/r6P/8 w…</td><td>false</td></tr><tr><td>&quot;6k1/5p1p/4p3/8/5K2/6P1/r6P/8 b…</td><td>false</td></tr><tr><td>&quot;8/7R/1Pp3p1/1nP2k2/2K5/8/8/8 b…</td><td>true</td></tr><tr><td>&quot;8/7R/1Pp5/1nP2kp1/2K5/8/8/8 w …</td><td>true</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;8/8/8/5p2/5p1p/1kp4P/p7/1K6 w …</td><td>false</td></tr><tr><td>&quot;8/8/8/5p2/5p1p/1kp4P/p7/K7 b -…</td><td>false</td></tr><tr><td>&quot;8/8/8/5p2/2k2p1p/2p4P/p7/K7 w …</td><td>false</td></tr><tr><td>&quot;8/8/1p6/pkp2K2/5B2/1P3P2/8/8 b…</td><td>true</td></tr><tr><td>&quot;8/8/1p6/p1p2K2/1k3B2/1P3P2/8/8…</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (148_818_672, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ fen                             ┆ win   │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ bool  │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ r5k1/5p1p/4p3/8/8/4K1P1/7P/8 b… ┆ false │\n",
       "│ 6k1/5p1p/4p3/8/8/4K1P1/r6P/8 w… ┆ false │\n",
       "│ 6k1/5p1p/4p3/8/5K2/6P1/r6P/8 b… ┆ false │\n",
       "│ 8/7R/1Pp3p1/1nP2k2/2K5/8/8/8 b… ┆ true  │\n",
       "│ 8/7R/1Pp5/1nP2kp1/2K5/8/8/8 w … ┆ true  │\n",
       "│ …                               ┆ …     │\n",
       "│ 8/8/8/5p2/5p1p/1kp4P/p7/1K6 w … ┆ false │\n",
       "│ 8/8/8/5p2/5p1p/1kp4P/p7/K7 b -… ┆ false │\n",
       "│ 8/8/8/5p2/2k2p1p/2p4P/p7/K7 w … ┆ false │\n",
       "│ 8/8/1p6/pkp2K2/5B2/1P3P2/8/8 b… ┆ true  │\n",
       "│ 8/8/1p6/p1p2K2/1k3B2/1P3P2/8/8… ┆ true  │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc1c0224-bb55-43f1-a5af-9c6e8174ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndgameDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, df, shuffle=False):\n",
    "        self.df = df\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "\n",
    "        if worker_info is None:\n",
    "            # Single-process data loading\n",
    "            start = 0\n",
    "            end = len(self.df)\n",
    "        else:\n",
    "            # In a worker process\n",
    "            per_worker = len(self.df) // worker_info.num_workers\n",
    "            worker_id = worker_info.id\n",
    "            start = worker_id * per_worker\n",
    "            end = start + per_worker if worker_id != worker_info.num_workers - 1 else len(self.df)\n",
    "\n",
    "        # Only iterate over your slice\n",
    "        for sub in self.df[start:end].iter_slices(512):\n",
    "            rows = [\n",
    "                (fen_to_onehot(row[0]), torch.tensor(row[1], dtype=torch.float32))\n",
    "                for row in sub.iter_rows()\n",
    "            ]\n",
    "            if self.shuffle:\n",
    "                random.shuffle(rows)\n",
    "            yield from rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64b3a857-4ca6-4bea-95a9-e7f96745ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = EndgameDataset(df.slice(0, 100_000))\n",
    "train_dataset = EndgameDataset(df.slice(100_000), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ff89bd2-08e0-4dc6-9c04-3d3d72f42735",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512 * 20, num_workers=31)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=512 * 2, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "305dd738-ea26-4e52-b709-be26f9ada774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline():\n",
    "    def material_count_predict_batch(inputs):\n",
    "        return (inputs[:, DIM] >= 0).clone().detach().unsqueeze(1)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            preds = material_count_predict_batch(inputs)\n",
    "            correct += (preds.squeeze() == labels).sum().item()\n",
    "            total += len(labels)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Material count prediction acc: {accuracy:.4f}\")  # ~90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8478b329-befd-4f02-9044-868a92d787aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallEndgameNet(lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(DIM, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        acc = (preds == y.unsqueeze(1)).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5af59860-5484-4e90-a64f-e472c85bec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "\n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | Sequential        | 29.8 K | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "29.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174233360cca441db34636e149e85145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42585e8f6ce34c31b2ef73d08b7903f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44491af02e94c03b2af8468f15689b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "small_model = SmallEndgameNet()\n",
    "trainer = lightning.pytorch.Trainer(max_epochs=1, limit_train_batches=1.0, accelerator=\"auto\")\n",
    "trainer.fit(small_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61416860-a7e9-4817-b049-5eee664fc8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeEndgameNet(lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LayerNorm(DIM),\n",
    "\n",
    "            nn.Linear(DIM, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        acc = (preds == y.unsqueeze(1)).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c36e9057-2023-4c08-963e-0c43af7407b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "\n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | Sequential        | 1.6 M  | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.442     Total estimated model params size (MB)\n",
      "16        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7e57ca7f0743f99e5ea5e9ff00952c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d603a5f4eed149efbc9a6c14fe86f4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fd80cb37884b8894960b4da5bd46b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "large_model = LargeEndgameNet()\n",
    "trainer = lightning.pytorch.Trainer(max_epochs=1, limit_train_batches=1.0, accelerator=\"auto\")\n",
    "trainer.fit(large_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c256a18a-c917-4b48-bc55-031eca2e9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrowEndgameNet(lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(DIM, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1),\n",
    "        )\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.unsqueeze(1).float())\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        acc = (preds == y.unsqueeze(1)).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1559c30-cafc-4283-9351-5aefb8a9e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "\n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model   | Sequential        | 30.5 K | train\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "30.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "30.5 K    Total params\n",
      "0.122     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5763f955dd4ea7b38d45b135f395e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec69ec27cdc4132abbed5ae8e52af6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7dfc196dd0c4800a90757426cd59330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "narrow_model = NarrowEndgameNet()\n",
    "trainer = lightning.pytorch.Trainer(max_epochs=1, limit_train_batches=1.0, accelerator=\"auto\")\n",
    "trainer.fit(narrow_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849efb88-9e99-459a-832e-ef7785928d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
